{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML4 Notebook\n",
    "\n",
    "In this course, we consider binary classifiers. For now, let's view this as a black box that takes in a data point $\\mathbf{x}_i$ (this could e.g. be an image), and outputs a decision between one of two classes (e.g. cat or dog)\n",
    "\n",
    "<img src=\"./classifier.png\" title=\"classifier\"/>\n",
    "\n",
    "To produce a classifier we need a dataset, which we split into three subsets:\n",
    "\n",
    "- The **training set** is used the train the classifier\n",
    "- The **validation set** is used to tune the classifier's hyperparameters (we won't delve into this further in these notebooks)\n",
    "- The **test set** is used to evaluate how good the classifier is \n",
    "\n",
    "In this notebook, and in the following notebooks we are going to use a **customised version of the iris dataset**\n",
    "and consider **the classification task of determining if a flower is (i) versicolor or (ii) virginica.** We will throw away the third class (setosas).\n",
    "\n",
    "Note: multi-way classification (e.g. between 3 or more classes) is possible but will keep everything as two classes for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets # If you are running this locally, then `pip install sklearn` in your Python environment.\n",
    "\n",
    "iris = sklearn.datasets.load_iris()\n",
    "X = np.load('iris_standardised.npy') # Load our standardised iris data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating our sets\n",
    "\n",
    "We are going to learn classifiers using **supervised learning algorithms**. This means we need to provide a class label for each data point.\n",
    "\n",
    "We are now going to load in the iris dataset, throw away the setosas, and split the remaining data into the three sets (train/val/test) with corresponding vectors for class labels. \n",
    "\n",
    "**Note: Manually splitting up a dataset is fairly tedious. Code will be provided to do it for you in the coursework lab.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we are going to create a matrix `X_b` that contains only the veriscolor, and virginica data points. We can do this by looking at the following arrays:\n",
    "\n",
    "- `iris.target` is an array of size $150$ where `iris.target[i]` is a numbered label for data point i\n",
    "- `iris.target_names` tells you which species each numbered label corresponds to\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.target_names)\n",
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the target of data point `X[i,:]` by looking at `iris.target[i]`. If this is a 0 then it is a setosa. If this is a 1 it is a versicolor and if it is 2 it is virginica. \n",
    "\n",
    "We only want veriscolors and virginicas so we filter our data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = np.where(iris.target != 0)[0] # Get targets that aren't zero\n",
    "X_b = X[valid_data,:] # Get corresponding data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that for supervised learning algorithms, we need to provide class labels. Let's create a vector `y_b` where `y_b[i]` is 0 for veriscolors, and 1 for virginicas for `X_b[i,:]`. We can do this easily because we know that our remaining data is 50 versicolors followed by 50 virginicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_b = np.concatenate([np.zeros(50), np.ones(50)])\n",
    "print(y_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to split this into three sets. We are going to split our data with the ratio 40/20/40 into train/val/test at random.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5) # Set a random seed\n",
    "\n",
    "indices = np.array([i for i in range(100)]) # The numbers 0-99\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_b[indices[0:40]]\n",
    "X_val = X_b[indices[40:60]]\n",
    "X_test = X_b[indices[60::]]\n",
    "\n",
    "y_train = y_b[indices[0:40]]\n",
    "y_val = y_b[indices[40:60]]\n",
    "y_test = y_b[indices[60::]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it. We'll now save these for use in later notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('iris_splits', X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
