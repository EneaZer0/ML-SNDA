{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML1 Notebook\n",
    "\n",
    "Each topic in this part of the course will have an accompanying Python notebook, where we can implement the concepts introduced using code. \n",
    "\n",
    "The key points from the video are that\n",
    "- We can represent data points using vectors\n",
    "- These can be stacked into a matrix to represent a whole dataset\n",
    "- We can standardise our data to prevent large measurements from dominating \n",
    "\n",
    "We will examine these concepts by exploring the Iris flower dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representing a datapoint\n",
    "\n",
    "Many of you will be familiar with the Iris flower dataset from PSE2. It was composed by Ronald Fisher in 1936. It consists of 150 data points, each corresponding to a particular iris flower.\n",
    "\n",
    "Each data point consists of 4 measurements (in cm). The sepal length, sepal width, petal length, and petal width of an iris.\n",
    "\n",
    "<img src=\"./iris.png\" title=\"iris\"/>\n",
    "\n",
    "We can represent this using a 4D vector. In Python, we represent vectors using NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our data point x is represented by [3.6 4.1 1.5 0.7]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # Import the numpy package\n",
    "\n",
    "x = np.array([3.6, 4.1, 1.5, 0.7]) # Create a numpy array to represent a vector.\n",
    "print(f'Our data point x is represented by {x}') # F-strings are a nice way to print!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representing a dataset\n",
    "\n",
    "We now have `x` which contains the measurements for the flower above. This is a **single data point** represented by a vector. We can represent an entire dataset simply by stacking the vectors for all the different data points to form a matrix.\n",
    "\n",
    "<img src=\"./irisdataset.png\" title=\"irisdataset\"/>\n",
    "\n",
    "\n",
    "\n",
    "This has already been done for us in the `sklearn` package for the Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our dataset X is represented by \n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets # If you are running this locally, then `pip install sklearn` in your Python environment.\n",
    "iris = sklearn.datasets.load_iris() # Load the iris dataset\n",
    "X = iris.data # Assign the dataset matrix to X\n",
    "print(f'Our dataset X is represented by \\n {X}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a matrix with 150 rows, where each **row** corresponds to a single data point. Each **column** corresponds to one of the four measurements for each data point; these are consistent (i.e. each column is measuring the same thing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardising your data\n",
    "\n",
    "In the video we introduce the concept of **standardising data.** This can prevent large measurements from dominating. A quick look at the dataset above shows that the first column (sepal length) has the largest values.\n",
    "\n",
    "This can be done by computing the mean and standard deviation of each measurement (column) across data points and then subtracting them from their respective columns. We can do this concisely in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column means are [5.84 3.06 3.76 1.2 ]\n",
      "The column stds are [0.83 0.43 1.76 0.76]\n"
     ]
    }
   ],
   "source": [
    "column_means = X.mean(0) # This means take the mean across columns\n",
    "print(f'The column means are {np.round(column_means,2)}') # Rounding to 2 DP\n",
    "\n",
    "column_stds = X.std(0) # This means take the std across columns\n",
    "print(f'The column stds are {np.round(column_stds,2)}') # Rounding to 2 DP\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the video, we can now subtract the mean, and divide by the standard deviation in each column. Remember that when we divide it is safe to add a small constant to the denominator to prevent division by zero!\n",
    "\n",
    "<img src=\"./standardise.png\" title=\"standardise\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-8 # A small constant to prevent division by zero\n",
    "X_s = (X - column_means)/(column_stds + eps) # Standardise\n",
    "X_s = np.round(X_s, 2) # Round to 2 d.p."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has this done the job? Let's look at the new column means and stds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column means are [ 0.  0. -0. -0.]\n",
      "The column stds are [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "column_means = X_s.mean(0) # This means take the mean across columns\n",
    "print(f'The column means are {np.round(column_means,2)}')\n",
    "\n",
    "column_stds = X_s.std(0) # This means take the std across columns\n",
    "print(f'The column stds are {np.round(column_stds,2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is now standardised!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.9   1.02 -1.34 -1.32]\n",
      " [-1.14 -0.13 -1.34 -1.32]\n",
      " [-1.39  0.33 -1.4  -1.32]\n",
      " [-1.51  0.1  -1.28 -1.32]\n",
      " [-1.02  1.25 -1.34 -1.32]\n",
      " [-0.54  1.94 -1.17 -1.05]\n",
      " [-1.51  0.79 -1.34 -1.18]\n",
      " [-1.02  0.79 -1.28 -1.32]\n",
      " [-1.75 -0.36 -1.34 -1.32]\n",
      " [-1.14  0.1  -1.28 -1.45]\n",
      " [-0.54  1.48 -1.28 -1.32]\n",
      " [-1.26  0.79 -1.23 -1.32]\n",
      " [-1.26 -0.13 -1.34 -1.45]\n",
      " [-1.87 -0.13 -1.51 -1.45]\n",
      " [-0.05  2.17 -1.45 -1.32]\n",
      " [-0.17  3.09 -1.28 -1.05]\n",
      " [-0.54  1.94 -1.4  -1.05]\n",
      " [-0.9   1.02 -1.34 -1.18]\n",
      " [-0.17  1.71 -1.17 -1.18]\n",
      " [-0.9   1.71 -1.28 -1.18]\n",
      " [-0.54  0.79 -1.17 -1.32]\n",
      " [-0.9   1.48 -1.28 -1.05]\n",
      " [-1.51  1.25 -1.57 -1.32]\n",
      " [-0.9   0.56 -1.17 -0.92]\n",
      " [-1.26  0.79 -1.06 -1.32]\n",
      " [-1.02 -0.13 -1.23 -1.32]\n",
      " [-1.02  0.79 -1.23 -1.05]\n",
      " [-0.78  1.02 -1.28 -1.32]\n",
      " [-0.78  0.79 -1.34 -1.32]\n",
      " [-1.39  0.33 -1.23 -1.32]\n",
      " [-1.26  0.1  -1.23 -1.32]\n",
      " [-0.54  0.79 -1.28 -1.05]\n",
      " [-0.78  2.4  -1.28 -1.45]\n",
      " [-0.42  2.63 -1.34 -1.32]\n",
      " [-1.14  0.1  -1.28 -1.32]\n",
      " [-1.02  0.33 -1.45 -1.32]\n",
      " [-0.42  1.02 -1.4  -1.32]\n",
      " [-1.14  1.25 -1.34 -1.45]\n",
      " [-1.75 -0.13 -1.4  -1.32]\n",
      " [-0.9   0.79 -1.28 -1.32]\n",
      " [-1.02  1.02 -1.4  -1.18]\n",
      " [-1.63 -1.74 -1.4  -1.18]\n",
      " [-1.75  0.33 -1.4  -1.32]\n",
      " [-1.02  1.02 -1.23 -0.79]\n",
      " [-0.9   1.71 -1.06 -1.05]\n",
      " [-1.26 -0.13 -1.34 -1.18]\n",
      " [-0.9   1.71 -1.23 -1.32]\n",
      " [-1.51  0.33 -1.34 -1.32]\n",
      " [-0.66  1.48 -1.28 -1.32]\n",
      " [-1.02  0.56 -1.34 -1.32]\n",
      " [ 1.4   0.33  0.54  0.26]\n",
      " [ 0.67  0.33  0.42  0.4 ]\n",
      " [ 1.28  0.1   0.65  0.4 ]\n",
      " [-0.42 -1.74  0.14  0.13]\n",
      " [ 0.8  -0.59  0.48  0.4 ]\n",
      " [-0.17 -0.59  0.42  0.13]\n",
      " [ 0.55  0.56  0.54  0.53]\n",
      " [-1.14 -1.51 -0.26 -0.26]\n",
      " [ 0.92 -0.36  0.48  0.13]\n",
      " [-0.78 -0.82  0.08  0.26]\n",
      " [-1.02 -2.43 -0.15 -0.26]\n",
      " [ 0.07 -0.13  0.25  0.4 ]\n",
      " [ 0.19 -1.97  0.14 -0.26]\n",
      " [ 0.31 -0.36  0.54  0.26]\n",
      " [-0.29 -0.36 -0.09  0.13]\n",
      " [ 1.04  0.1   0.36  0.26]\n",
      " [-0.29 -0.13  0.42  0.4 ]\n",
      " [-0.05 -0.82  0.19 -0.26]\n",
      " [ 0.43 -1.97  0.42  0.4 ]\n",
      " [-0.29 -1.28  0.08 -0.13]\n",
      " [ 0.07  0.33  0.59  0.79]\n",
      " [ 0.31 -0.59  0.14  0.13]\n",
      " [ 0.55 -1.28  0.65  0.4 ]\n",
      " [ 0.31 -0.59  0.54  0.  ]\n",
      " [ 0.67 -0.36  0.31  0.13]\n",
      " [ 0.92 -0.13  0.36  0.26]\n",
      " [ 1.16 -0.59  0.59  0.26]\n",
      " [ 1.04 -0.13  0.71  0.66]\n",
      " [ 0.19 -0.36  0.42  0.4 ]\n",
      " [-0.17 -1.05 -0.15 -0.26]\n",
      " [-0.42 -1.51  0.02 -0.13]\n",
      " [-0.42 -1.51 -0.03 -0.26]\n",
      " [-0.05 -0.82  0.08  0.  ]\n",
      " [ 0.19 -0.82  0.76  0.53]\n",
      " [-0.54 -0.13  0.42  0.4 ]\n",
      " [ 0.19  0.79  0.42  0.53]\n",
      " [ 1.04  0.1   0.54  0.4 ]\n",
      " [ 0.55 -1.74  0.36  0.13]\n",
      " [-0.29 -0.13  0.19  0.13]\n",
      " [-0.42 -1.28  0.14  0.13]\n",
      " [-0.42 -1.05  0.36  0.  ]\n",
      " [ 0.31 -0.13  0.48  0.26]\n",
      " [-0.05 -1.05  0.14  0.  ]\n",
      " [-1.02 -1.74 -0.26 -0.26]\n",
      " [-0.29 -0.82  0.25  0.13]\n",
      " [-0.17 -0.13  0.25  0.  ]\n",
      " [-0.17 -0.36  0.25  0.13]\n",
      " [ 0.43 -0.36  0.31  0.13]\n",
      " [-0.9  -1.28 -0.43 -0.13]\n",
      " [-0.17 -0.59  0.19  0.13]\n",
      " [ 0.55  0.56  1.27  1.71]\n",
      " [-0.05 -0.82  0.76  0.92]\n",
      " [ 1.52 -0.13  1.22  1.19]\n",
      " [ 0.55 -0.36  1.05  0.79]\n",
      " [ 0.8  -0.13  1.16  1.32]\n",
      " [ 2.13 -0.13  1.62  1.19]\n",
      " [-1.14 -1.28  0.42  0.66]\n",
      " [ 1.77 -0.36  1.44  0.79]\n",
      " [ 1.04 -1.28  1.16  0.79]\n",
      " [ 1.64  1.25  1.33  1.71]\n",
      " [ 0.8   0.33  0.76  1.05]\n",
      " [ 0.67 -0.82  0.88  0.92]\n",
      " [ 1.16 -0.13  0.99  1.19]\n",
      " [-0.17 -1.28  0.71  1.05]\n",
      " [-0.05 -0.59  0.76  1.58]\n",
      " [ 0.67  0.33  0.88  1.45]\n",
      " [ 0.8  -0.13  0.99  0.79]\n",
      " [ 2.25  1.71  1.67  1.32]\n",
      " [ 2.25 -1.05  1.79  1.45]\n",
      " [ 0.19 -1.97  0.71  0.4 ]\n",
      " [ 1.28  0.33  1.1   1.45]\n",
      " [-0.29 -0.59  0.65  1.05]\n",
      " [ 2.25 -0.59  1.67  1.05]\n",
      " [ 0.55 -0.82  0.65  0.79]\n",
      " [ 1.04  0.56  1.1   1.19]\n",
      " [ 1.64  0.33  1.27  0.79]\n",
      " [ 0.43 -0.59  0.59  0.79]\n",
      " [ 0.31 -0.13  0.65  0.79]\n",
      " [ 0.67 -0.59  1.05  1.19]\n",
      " [ 1.64 -0.13  1.16  0.53]\n",
      " [ 1.89 -0.59  1.33  0.92]\n",
      " [ 2.49  1.71  1.5   1.05]\n",
      " [ 0.67 -0.59  1.05  1.32]\n",
      " [ 0.55 -0.59  0.76  0.4 ]\n",
      " [ 0.31 -1.05  1.05  0.26]\n",
      " [ 2.25 -0.13  1.33  1.45]\n",
      " [ 0.55  0.79  1.05  1.58]\n",
      " [ 0.67  0.1   0.99  0.79]\n",
      " [ 0.19 -0.13  0.59  0.79]\n",
      " [ 1.28  0.1   0.93  1.19]\n",
      " [ 1.04  0.1   1.05  1.58]\n",
      " [ 1.28  0.1   0.76  1.45]\n",
      " [-0.05 -0.82  0.76  0.92]\n",
      " [ 1.16  0.33  1.22  1.45]\n",
      " [ 1.04  0.56  1.1   1.71]\n",
      " [ 1.04 -0.13  0.82  1.45]\n",
      " [ 0.55 -1.28  0.71  0.92]\n",
      " [ 0.8  -0.13  0.82  1.05]\n",
      " [ 0.43  0.79  0.93  1.45]\n",
      " [ 0.07 -0.13  0.76  0.79]]\n"
     ]
    }
   ],
   "source": [
    "print(X_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The measurements aren't in cm any more (some of the values are negative!) but **this is not important**. It is simply a linear rescaling. Large/positive is long and small/negative is short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('iris_standardised', X_s) # Save the standardised dataset for later use\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
