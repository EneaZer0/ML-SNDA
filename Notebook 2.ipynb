{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML2 Notebook\n",
    "\n",
    "### Dimensionality Reduction\n",
    "\n",
    "We have a dataset matrix $\\mathbf{X}\\in \\mathbb{R}^{N\\times D}$ that consists of $N$ data points, each of dimensionality $D$. We want to reduce the dimensionality of our dataset, so it takes up less space, and is easier to visualise. \n",
    "\n",
    "This means that we want a new dataset matrix $\\mathbf{X_D}\\in \\mathbb{R}^{N\\times M}$ that consists of $N$ data points, each of dimensionality $M$ where $M<D$. \n",
    "\n",
    "We can achieve this by using a transformation matrix $\\mathbf{W}\\in \\mathbb{R}^{D\\times M}$. This transforms our data to a lower dimension using $ \\mathbf{X_{D}} =  \\mathbf{X}\\mathbf{W}$.\n",
    "\n",
    "<img src=\"./transform1.png\" title=\"transform1\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's illustrate this on our (standardised) iris dataset ($N=150, D=4$). Consider the scenario where we want to reduce our data to 2D. This gives us $M=2$.\n",
    "\n",
    "$\\mathbf{W}$ in this case must be a $4\\times 2$ matrix. In this notebook we will use the following matrix for $\\mathbf{W}$:\n",
    "\n",
    "$\\mathbf{W}=\n",
    "\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1 \\\\\n",
    "0 & 0 \\\\\n",
    "0 & 0 \\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "This particular $\\mathbf{W}$ is **not optimal** and is used for illustration. You will find out how to get the optimal $\\mathbf{W}$ in the next video!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Import the numpy package\n",
    "\n",
    "X = np.load('iris_standardised.npy') # Load our standardised iris data\n",
    "\n",
    "print(f'Our dataset is represented by a matrix X that is of shape {X.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.array([[1,0],[0,1],[0,0],[0,0]]) # Create W\n",
    "X_D = X @ W # Multiple X by W\n",
    "print(X_D) # Print our reduced dimensionality dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Our dimensionality-reduced dataset is represented by a matrix X_D that is of shape {X_D.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have chosen our $\\mathbf{W}$ so that the transformed dataset keeps the first two dimensions of $\\mathbf{X}$ and ignores the other two. As I mentioned, this isn't optimal, as we're throwing away information that might be valuable!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction\n",
    "\n",
    "Our matrix $\\mathbf{W}$ can be used to reduce the dimensionality of our dataset using $ \\mathbf{X_{D}} = \\mathbf{X}\\mathbf{W}$\n",
    "\n",
    "We also want to use $\\mathbf{W}^\\text{T}$ to try and reconstruct our original data from $ \\mathbf{X_{D}}$ using $ \\mathbf{\\widetilde{X}} =  \\mathbf{X_D}\\mathbf{W^T}$ where $\\mathbf{\\widetilde{X}}$ is our reconstructed dataset.\n",
    "\n",
    "<img src=\"./transform2.png\" title=\"transform2\"/>\n",
    "\n",
    "\n",
    "\n",
    "Why do we want this? Well, **this setup lets us evaluate how good the transformation $\\mathbf{W}$ is!**  If our reconstructed dataset resembles our original dataset then our transformation $\\mathbf{W}$ was good; it was able to transform the dataset to a lower dimensional space, while keeping most of the important information intact.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use $\\mathbf{W}^\\text{T}$ to bring our iris dataset back up to 4 dimensions, in an attempt to reconstruct the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tilde = X_D @ W.T\n",
    "print(X_tilde)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're back in 4 dimensions! But we have lost all the values in the last two columns. These are now zero. We know that this is bad, but we can quantify how bad it is by computing the **reconstruction error**.\n",
    "\n",
    "<img src=\"./recon.png\" title=\"recon\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 150 # Number of data points\n",
    "E = 0 # Start our reconstruction error as 0 and then add to it\n",
    "for i in range(N):\n",
    "    E += np.linalg.norm(X[i,:]-X_tilde[i,:]) # Add the error for each data point.\n",
    "\n",
    "print(f'Reconstruction error is {E:0.2f}. This is bad!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the loop above is illustrative. As is often the case in Python, we can do everything quickly without loops if we think about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = np.sum(np.sum((X-X_tilde)**2,1)**.5)\n",
    "# Subtract X from X_tilde, square all the entries, sum across each row, take the square root, sum\n",
    "print(E)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
